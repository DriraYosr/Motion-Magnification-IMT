{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf5RrhNaDejC"
   },
   "source": [
    "# An offline demo for the \"Learning-based Video Motion Magnification\" (ECCV 2018)\n",
    "\n",
    "# Official repo: https://github.com/12dmodel/deep_motion_mag\n",
    "# My repo: https://github.com/ZhengPeng7/motion_magnification_learning-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to set your python Kernel for notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7Ghq0laIGq4"
   },
   "source": [
    "## Preparations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWvGFo9yECoa"
   },
   "source": [
    "### Install python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nI-Hq9WK5xNg",
    "outputId": "4c55ba46-ee51-4752-8dd1-deab4ffe704e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\drira yosr\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\drira yosr\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -r requirements.txt\n",
    "!pip install --quiet gdown mediapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhA7-odZEHQW"
   },
   "source": [
    "### Download and load the well-trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUX3pb77Axr0",
    "outputId": "11164c11-73dc-4418-8248-dfb9ab66d535"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exï¿½cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ZhengPeng7/motion_magnification_learning-based/releases/download/v1.0/magnet_epoch12_loss7.28e-02.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quAf0VARHAPM",
    "outputId": "7eb23fde-56e9-4797-dd0a-091b559aaec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please load train_mf.txt if you want to do training.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'magnet_epoch12_loss7.28e-02.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16868\\17110111.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'magnet_epoch12_loss7.28e-02.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMagNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Drira Yosr\\Desktop\\Computational imaging\\project\\motion_magnification_learning-based\\callbacks.py\u001b[0m in \u001b[0;36mgen_state_dict\u001b[1;34m(weights_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgen_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mst_ks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mst_vs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Drira Yosr\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Drira Yosr\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Drira Yosr\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'magnet_epoch12_loss7.28e-02.pth'"
     ]
    }
   ],
   "source": [
    "from magnet import MagNet\n",
    "from callbacks import gen_state_dict\n",
    "from config import Config\n",
    "\n",
    "\n",
    "# config\n",
    "config = Config()\n",
    "# Load weights\n",
    "weights_path = 'magnet_epoch12_loss7.28e-02.pth'\n",
    "ep = int(weights_path.split('epoch')[-1].split('_')[0])\n",
    "state_dict = gen_state_dict(weights_path)\n",
    "\n",
    "model_test = MagNet().cuda()\n",
    "model_test.load_state_dict(state_dict)\n",
    "model_test.eval()\n",
    "print(\"Loading weights:\", weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AM4n9P-iaNG"
   },
   "source": [
    "# Preprocess\n",
    "\n",
    "Make the video to frameAs/frameBs/frameCs.\n",
    "\n",
    "Let's take the guitar.mp4 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnJSrX43vlgy",
    "outputId": "bb3fec89-a7f1-4246-a4c7-7f08548ca905"
   },
   "outputs": [],
   "source": [
    "# Download some example video from my google-drive or upload your own video.\n",
    "# !gdown 1hNZ02vnSO04FYS9jkx2OjProYHIvwdkB  # guitar.avi\n",
    "!gdown 1XGC2y4Lshd9aBiBxwkTuT_IA79n-WNST  # baby.avi\n",
    "# !gdown 1QGOWuR0swF7_eHharTztlkEDz0hlfmU4  # zhiyin.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pd9lV4mCHU9v"
   },
   "source": [
    "# Set VIDEO_NAME here, e.g., guitar, baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0v0Uacfmtib",
    "outputId": "01383531-8a69-42f5-8b7c-a280acff41c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "Input #0, avi, from 'baby.avi':\n",
      "  Duration: 00:00:10.03, start: 0.000000, bitrate: 15411 kb/s\n",
      "    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 960x544 [SAR 1:1 DAR 30:17], 15399 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x561bdb17b380] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0mOutput #0, image2, to 'baby/%06d.png':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: png, rgb24, 960x544 [SAR 1:1 DAR 30:17], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 png\n",
      "frame=  301 fps= 48 q=-0.0 Lsize=N/A time=00:00:10.03 bitrate=N/A speed= 1.6x    \n",
      "video:187776kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ACB-Processing on baby\n"
     ]
    }
   ],
   "source": [
    "# Turn the video into frames and make them into frame_ACB format.\n",
    "file_to_be_maged = 'baby.avi'   # 'guitar.avi'\n",
    "video_name = file_to_be_maged.split('.')[0]\n",
    "video_format = '.' + file_to_be_maged.split('.')[-1]\n",
    "\n",
    "\n",
    "sh_file = 'VIDEO_NAME={}\\nVIDEO_FORMAT={}'.format(video_name, video_format) + \"\"\"\n",
    "\n",
    "\n",
    "mkdir ${VIDEO_NAME}\n",
    "ffmpeg -i ${VIDEO_NAME}${VIDEO_FORMAT} -f image2 ${VIDEO_NAME}/%06d.png\n",
    "python make_frameACB.py ${VIDEO_NAME}\n",
    "mkdir test_dir\n",
    "mv ${VIDEO_NAME} test_dir\n",
    "\"\"\"\n",
    "with open('test_preproc.sh', 'w') as file:\n",
    "  file.write(sh_file)\n",
    "\n",
    "!bash test_preproc.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeOYfifiGUPq"
   },
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXz3mYanz07-",
    "outputId": "9d526b43-6f76-404c-fa91-235ea6b5ee72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test image couples: 300\n",
      "100, 200, 300, res_baby/baby/baby_amp10.avi has been done.\n",
      "100, 200, 300, res_baby/baby/baby_amp25.avi has been done.\n",
      "100, 200, 300, res_baby/baby/baby_amp50.avi has been done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from data import get_gen_ABC, unit_postprocessing, numpy2cuda, resize2d\n",
    "\n",
    "\n",
    "# testsets = '+'.join(['baby', 'guitar', 'gun', 'drone', 'cattoy', 'water'][:])\n",
    "for testset in [video_name]:\n",
    "    dir_results = 'res_' + testset\n",
    "    if not os.path.exists(dir_results):\n",
    "        os.makedirs(dir_results)\n",
    "\n",
    "    config.data_dir = 'test_dir'\n",
    "    data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
    "    print('Number of test image couples:', data_loader.data_len)\n",
    "    vid_size = cv2.imread(data_loader.paths[0]).shape[:2][::-1]\n",
    "\n",
    "    # Test\n",
    "    #Magification factor here:{amp}\n",
    "    for amp in [10, 25, 50]:\n",
    "        frames = []\n",
    "        data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
    "        for idx_load in range(0, data_loader.data_len, data_loader.batch_size):\n",
    "            if (idx_load+1) % 100 == 0:\n",
    "                print('{}'.format(idx_load+1), end=', ')\n",
    "            batch_A, batch_B = data_loader.gen_test()\n",
    "            amp_factor = numpy2cuda(amp)\n",
    "            for _ in range(len(batch_A.shape) - len(amp_factor.shape)):\n",
    "                amp_factor = amp_factor.unsqueeze(-1)\n",
    "            with torch.no_grad():\n",
    "                y_hats = model_test(batch_A, batch_B, 0, 0, amp_factor, mode='evaluate')\n",
    "            for y_hat in y_hats:\n",
    "                y_hat = unit_postprocessing(y_hat, vid_size=vid_size)\n",
    "                frames.append(y_hat)\n",
    "                if len(frames) >= data_loader.data_len:\n",
    "                    break\n",
    "            if len(frames) >= data_loader.data_len:\n",
    "                break\n",
    "        data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
    "        frames = [unit_postprocessing(data_loader.gen_test()[0], vid_size=vid_size)] + frames\n",
    "\n",
    "        # Make videos of framesMag\n",
    "        video_dir = os.path.join(dir_results, testset)\n",
    "        if not os.path.exists(video_dir):\n",
    "            os.makedirs(video_dir)\n",
    "        FPS = 30\n",
    "        video_save_path = os.path.join(video_dir, '{}_amp{}{}'.format(testset, amp, video_format))\n",
    "        out = cv2.VideoWriter(\n",
    "            video_save_path,\n",
    "            cv2.VideoWriter_fourcc(*'DIVX'),\n",
    "            FPS, frames[0].shape[-2::-1]\n",
    "        )\n",
    "        for frame in frames:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            cv2.putText(frame, 'amp_factor={}'.format(amp), (7, 37),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255), thickness=2)\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "        print('{} has been done.'.format(video_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the amplified video here\n",
    "from glob import glob\n",
    "import mediapy\n",
    "\n",
    "\n",
    "video_save_paths = [file_to_be_maged] + sorted(glob(os.path.join(dir_results, testset, '*')), key=lambda x: int(x.split('amp')[-1].split('.')[0]))\n",
    "\n",
    "video_dict = {}\n",
    "for video_save_path in video_save_paths[:]:\n",
    "  video_dict[video_save_path.split('/')[-1]] = mediapy.read_video(video_save_path)\n",
    "mediapy.show_videos(video_dict, fps=FPS, width=250, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
